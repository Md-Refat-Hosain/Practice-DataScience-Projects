{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2UpHjVOE6du",
        "outputId": "cb39ce7b-0094-4c28-edc6-826f17cd056e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sbn\n",
        "import statistics as st\n",
        "\n",
        "# Libraries For Text\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I love this movies!\"\n",
        "tokens = word_tokenize(text)\n",
        "tokens"
      ],
      "metadata": {
        "id": "AMmTutAYFQ_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f1e58d-2fb5-4761-9a1b-d558c94bd775"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'love', 'this', 'movies', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lower_tokens = [token.lower() for token in tokens]\n",
        "lower_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcl5xAElNWt-",
        "outputId": "9fd80f3e-ed89-4a64-e78b-c96a9885877e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'love', 'this', 'movies', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering Symbolic sign like  ,!~?"
      ],
      "metadata": {
        "id": "QB0SNKwIOlGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in lower_tokens if token not in stopwords]\n",
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIbpqcXYOyMP",
        "outputId": "aa5580d6-9b75-47a2-95d2-c912dccf9bc9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love', 'movies', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Removing exclamatory sign (!)\n",
        "\n",
        "import re\n",
        "\n",
        "clean_tokens = [re.sub(r'[^\\w\\s]' , '' , token) for token in filtered_tokens]\n",
        "clean_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XSGeydBQDUP",
        "outputId": "04d7d31d-a9ef-4b21-9c0e-7ce99ca3e00e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love', 'movies', '']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for feature extraction"
      ],
      "metadata": {
        "id": "1aI73-jpUENd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
      ],
      "metadata": {
        "id": "4vBBH-QfUKJZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['I love this movie!' , 'This movie is great.' , \"I don't like this movie.\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(  X.toarray() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYwaScVKUVNr",
        "outputId": "0506ead4-3928-4b71-bd40-5bb649b673b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['don' 'great' 'is' 'like' 'love' 'movie' 'this']\n",
            "[[0 0 0 0 1 1 1]\n",
            " [0 1 1 0 0 1 1]\n",
            " [1 0 0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['I love this movie!' , 'This movie is great.' , \"I don't like this movie.\"]\n",
        "Vectorizer = TfidfVectorizer()\n",
        "X = Vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(  X.toarray() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC2mVOI0ZOsN",
        "outputId": "11409ba9-2f50-428b-ffcb-cdd50c90d2fc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['don' 'great' 'is' 'like' 'love' 'movie' 'this']\n",
            "[[0.         0.         0.         0.         0.76749457 0.45329466\n",
            "  0.45329466]\n",
            " [0.         0.6088451  0.6088451  0.         0.         0.35959372\n",
            "  0.35959372]\n",
            " [0.6088451  0.         0.         0.6088451  0.         0.35959372\n",
            "  0.35959372]]\n"
          ]
        }
      ]
    }
  ]
}