
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sbn
import statistics as st

# Libraries For Text

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import confusion_matrix
%matplotlib inline

text = "I love this movies!"
tokens = word_tokenize(text)
tokens


lower_tokens = [token.lower() for token in tokens]
lower_tokens

# Filtering Symbolic sign like  ,!~? 

stopwords = set(stopwords.words('english'))
filtered_tokens = [token for token in lower_tokens if token not in stopwords]
filtered_tokens


# Now Removing exclamatory sign (!)

import re

clean_tokens = [re.sub(r'[^\w\s]' , '' , token) for token in filtered_tokens]
clean_tokens

# Import libraries for feature extraction

from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer

corpus = ['I love this movie!' , 'This movie is great.' , "I don't like this movie."]
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)
print(vectorizer.get_feature_names_out())
print(  X.toarray() )

corpus = ['I love this movie!' , 'This movie is great.' , "I don't like this movie."]
Vectorizer = TfidfVectorizer()
X = Vectorizer.fit_transform(corpus)
print(vectorizer.get_feature_names_out())
print(  X.toarray() )


#   EDN 
